# ros_moving_object

## 1. Introduction
ROS moving object package is addressing moving objects based on messages generated by
Object Analytics [ros_object_analytics](https://github.com/intel/ros_object_analytics).
ros_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding
motion information. Such information can extend robot's ability of motion planing and collision avoidance.

## 2. Output Topics

ros_moving_object package publishes some messages to indicate different status/data.
 - **/moving\_object/moving\_objects** merges info from the 3 input messages into one message.

## 3. Build and Runtime dependencies

  ROS packages from [ros-kinetic-desktop-full](http://wiki.ros.org/kinetic/Installation/Ubuntu)
  * roscpp
  * std_msgs
  * sensor_msgs
  * geometry_msgs
  * message_filters
  * tf

  ROS packages from [Intel repo](https://github.com/intel)
  * [object\_analytics\_msgs](https://github.com/intel/ros_object_analytics/tree/master/object_analytics_msgs)
  * [object_msgs](https://github.com/intel/object_msgs)

## 4. Build Steps
  * to build
  ```bash
  cd ${ros_ws} # "ros_ws" is the catkin workspace root directory where this project is placed in
  catkin_make
  ```

  * to install
  ```bash
  catkin_make install
  ```
## 5. Launch Steps
   * Prerequisite

   ROS Moving Object package depends directly on ros_object_analytics, and indirectly on one of "state-of-the-art" algorithms. See more environment setup from [ros_object_analytics repo](https://github.com/intel/ros_object_analytics).

   * Launching commands

  Taking [ros_intel_movidius_ncs](https://github.com/intel/ros_intel_movidius_ncs) as default "state-of-the-art" algorithm.
  ```bash
  roslaunch realsense_ros_camera rs_camera.launch enable_pointcloud:=true enable_sync:=true
  roslaunch object_analytics_launch analytics_movidius_ncs.launch input_points:=/camera/points
  roslaunch moving_object moving_object.launch
  ```

## 6. Usage Sample - CA Policy
CA Policy is a sample ros package using ros_moving_object package to arbitrate suitable policies according to the detected obstacle types. CA Policy outputs policy name as topic *ca_policy* and acts the behaviors set to the given policy.

During robot navigation,  node ca_policy monitors the output topics of moving_object. If a person moves into camera's field of view and near robot's trajectory, node moving_object sends topics including such social info. Once node ca_policy receives such social info, ca_policy sends out topic with *social* CA Policy status, meanwhile, ca_policy triggers corresponding actions to reconfigure navigation stack's behavior and send notification. Otherwise, if there is no person seen by the camera (that is, there is no social information to node ca_policy), *normal* CA Policy would be sent out and another set of policy actions where are binded to normal CA policy would be triggered.

The supported policy actions vary according to the specified robot chassis:
- **Policy Actions supported on Turtlebot2:**
	- Dynamic Reconfiguration for navigation stack
	- Led Light notification
	- Beeper notification
- **Policy Actions supported on Waterbot:**
	- Dynamic Reconfiguration for navigation stack
	- Ledbelt notification

### 6.1 Output Topic
 - **/ca\_policy/ca\_policy**  notifies the current collision avoidance policy.
### 6.2 Build & Runtime Dependencies
  ROS packages from [ros-kinetic-desktop-full](http://wiki.ros.org/kinetic/Installation/Ubuntu)
  * roscpp
  * std_msgs
  * sensor_msgs
  * geometry_msgs
  * dynamic_reconfigure
  * kobuki_msgs

  ROS packages from [Intel repo](https://github.com/intel)
  * [moving_object_msgs](https://github.com/intel/ros_moving_object)

### 6.3 Launch CA Policy Sample Package
   * Prerequisite

   ROS CA Policy package depends indirectly on [ros navigation](http://wiki.ros.org/navigation) and one of supported robot chassises (turtlebot2 or [waterbot](http://www.yunji.com)). Make sure ros navigation is correctly launched on the chosen robot chassis.

   * Launching commands

  Taking turtlebot2 as example, and make sure moving_object (steps in section above) is already launched:
  ```bash
  roslaunch turtlebot_bringup minimal.launch
  roslaunch ca_policy ca_policy.launch
  roslaunch turtlebot_navigation gmapping_demo.launch
  roslaunch turtlebot_rviz_launchers view_navigation.launch (Optional)
  ```

### 6.4 Robot  Chassis Configuration

  Currently, *ca_policy* package supports turtlebot2 and [waterbot](http://www.yunji.com) robot chassises. Some parameters should be updated for robot chassis changing:
  * robot chassis: the name of robot name (currently  turtlebot | waterbot)
  * CaPolicies/config: the config file of each CA Policy.
#### 6.4.1 Enable Turtlebot2 Chassis
  Update param/ca_policy_common.yaml as:
  ```bash
  #CA Policies supported
  # Note that normal Policy must be set.
  CaPolicies:
    - {name: "normal",  config: "turtlebot/normal.yaml"}
    - {name: "social",  config: "turtlebot/social.yaml"}

  #maximum distance from robot to a person when social policy is enabled.
  max_detection_distance: 2.5

  #minimal interval in which social policy should be kept.
  min_interval: 5.0

  #The name of robot chassis, one of "waterbot" or "turtlebot"
  robot_base: turtlebot

  #social object source
  social_object_source: /moving_object/social_object
  ```
#### 6.4.2 Enable Water C1 Chassis 
  Update param/ca_policy_common.yaml as:
  ```bash
  #CA Policies supported
  # Note that normal Policy must be set.
  CaPolicies:
    - {name: "normal",  config: "waterbot/normal.yaml"}
    - {name: "social",  config: "waterbot/social.yaml"}

  #maximum distance from robot to a person when social policy is enabled.
  max_detection_distance: 2.5

  #minimal interval in which social policy should be kept.
  min_interval: 5.0

  #The name of robot chassis, one of "waterbot" or "turtlebot"
  robot_base: waterbot

  #social object source
  social_object_source: /moving_object/social_object
  ```
## 7. Known Issues

* Moving Object directly uses the frame_id passed through from Object Analytics package.

Curretnly, Obect Analytics uses frame_id "camera_depth_optical_frame" and its static transform. This frame is defined
for the default kinect RGB-D camera on turtlebot2 and for the default camera on waterbot. In the common cases, the
RGB-D camera used by Object Analytics package is always mounted with the same direction as the default one, so the bias
between the 2 camera's coordinates can be ignored.

* The accuracy of the calcualted velocity highly depends on that of the data delivered by Object Analytics package.

##### *Any security issue should be reported using process at https://01.org/security

